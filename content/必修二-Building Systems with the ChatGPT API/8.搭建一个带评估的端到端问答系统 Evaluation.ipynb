{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTQ1vHTz0mLz"
      },
      "source": [
        "# 第八章 搭建一个带评估的端到端问答系统\n",
        "\n",
        " - [一、环境配置](#一、环境配置)\n",
        " - [二、用于处理用户查询的链式 Prompt 系统](#二、用于处理用户查询的链式-Prompt-系统)\n",
        "     - [2.1 一个端到端实现问答的函数](#2.1-一个端到端实现问答的函数)\n",
        "     - [2.2 持续收集用户和助手消息的函数](#2.2-持续收集用户和助手消息的函数)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmwLemUw0mL1"
      },
      "source": [
        "在本章中，我们将搭建一个带评估的端到端问答系统，这个系统综合了之前多节课的内容，并加入了评估过程。\n",
        "\n",
        "1. 检查输入，确认其是否能通过审核 API 的审核。\n",
        "\n",
        "2. 如果通过了审核，我们将查找产品列表。\n",
        "\n",
        "3. 如果找到了产品，我们将尝试查找它们的相关信息。\n",
        "\n",
        "4. 我们使用模型回答用户提出的问题。\n",
        "\n",
        "5. 我们将通过审核 API 对生成的答案进行审核。\n",
        "\n",
        "如果没有被标记为有害的，我们将把答案返回给用户。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WkD-Evp0mL1"
      },
      "source": [
        "## 一、环境配置"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoI4N-0e0mL2"
      },
      "source": [
        "同上一章，我们首先需要配置使用 OpenAI API 的环境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MeTqKi2C0mL2",
        "outputId": "610317e9-e93c-4ca4-c624-88f34520dc6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'utils_en' from 'utils' (/usr/local/lib/python3.11/dist-packages/utils/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-74739705.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 使用英文 Prompt 的工具包\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils_en\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# 使用中文 Prompt 的工具包\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils_zh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'utils_en' from 'utils' (/usr/local/lib/python3.11/dist-packages/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# 配置 OpenAI KEY\n",
        "import os\n",
        "from openai import OpenAI\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "# 使用英文 Prompt 的工具包\n",
        "from utils import utils_en\n",
        "# 使用中文 Prompt 的工具包\n",
        "from utils import utils_zh\n",
        "\n",
        "import panel as pn  # 用于图形化界面\n",
        "pn.extension()\n",
        "\n",
        "OpenAiKey = userdata.get('openAiKey')\n",
        "\n",
        "client = OpenAI(\n",
        "        api_key=OpenAiKey,\n",
        "        base_url=\"https://ai.nengyongai.cn/v1/\"\n",
        "\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6xHYBfC0mL3"
      },
      "outputs": [],
      "source": [
        "def get_completion_from_messages(messages,\n",
        "                                 model=\"gpt-3.5-turbo\",\n",
        "                                 temperature=0,\n",
        "                                 max_tokens=500):\n",
        "    '''\n",
        "    封装一个访问 OpenAI GPT3.5 的函数\n",
        "\n",
        "    参数:\n",
        "    messages: 这是一个消息列表，每个消息都是一个字典，包含 role(角色）和 content(内容)。角色可以是'system'、'user' 或 'assistant’，内容是角色的消息。\n",
        "    model: 调用的模型，默认为 gpt-3.5-turbo(ChatGPT)，有内测资格的用户可以选择 gpt-4\n",
        "    temperature: 这决定模型输出的随机程度，默认为0，表示输出将非常确定。增加温度会使输出更随机。\n",
        "    max_tokens: 这决定模型输出的最大的 token 数。\n",
        "    '''\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature, # 这决定模型输出的随机程度\n",
        "        max_tokens=max_tokens, # 这决定模型输出的最大的 token 数\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnrKyKiL0mL4"
      },
      "source": [
        "## 二、用于处理用户查询的链式 Prompt 系统"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "803fcgLV0mL4"
      },
      "source": [
        "### 2.1 一个端到端实现问答的函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bRfXncB0mL4",
        "outputId": "6c01fea2-3273-472d-c9c8-50e0dc374b08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "第一步：输入通过 Moderation 检查\n",
            "第二步：抽取出商品列表\n",
            "第三步：查找抽取出的商品信息\n",
            "第四步：生成用户回答\n",
            "第五步：输出经过 Moderation 检查\n",
            "第六步：模型评估该回答\n",
            "第七步：模型赞同了该回答.\n",
            "The SmartX ProPhone is a powerful smartphone with a 6.1-inch display, 128GB storage, 12MP dual camera, and 5G capabilities. The FotoSnap DSLR Camera is a versatile camera with a 24.2MP sensor, 1080p video, 3-inch LCD, and interchangeable lenses. As for our TVs, we have a range of options including the CineView 4K TV with a 55-inch display, 4K resolution, HDR, and smart TV capabilities, the CineView 8K TV with a 65-inch display, 8K resolution, HDR, and smart TV capabilities, and the CineView OLED TV with a 55-inch display, 4K resolution, HDR, and smart TV capabilities. Do you have any specific questions about these products or would you like me to recommend a product based on your needs?\n"
          ]
        }
      ],
      "source": [
        "def process_user_message(user_input, all_messages, debug=True):\n",
        "    \"\"\"\n",
        "    对用户信息进行预处理\n",
        "\n",
        "    参数:\n",
        "    user_input : 用户输入\n",
        "    all_messages : 历史信息\n",
        "    debug : 是否开启 DEBUG 模式,默认开启\n",
        "    \"\"\"\n",
        "    # 分隔符\n",
        "    delimiter = \"```\"\n",
        "\n",
        "    # 第一步: 使用 OpenAI 的 Moderation API 检查用户输入是否合规或者是一个注入的 Prompt\n",
        "    response = client.moderations.create(input=user_input)\n",
        "    moderation_output = response.results[0]\n",
        "\n",
        "    # 经过 Moderation API 检查该输入不合规\n",
        "    if moderation_output[\"flagged\"]:\n",
        "        print(\"第一步：输入被 Moderation 拒绝\")\n",
        "        return \"抱歉，您的请求不合规\"\n",
        "\n",
        "    # 如果开启了 DEBUG 模式，打印实时进度\n",
        "    if debug: print(\"第一步：输入通过 Moderation 检查\")\n",
        "\n",
        "    # 第二步：抽取出商品和对应的目录，类似于之前课程中的方法，做了一个封装\n",
        "    category_and_product_response = utils_en.find_category_and_product_only(user_input, utils_en.get_products_and_category())\n",
        "    #print(category_and_product_response)\n",
        "    # 将抽取出来的字符串转化为列表\n",
        "    category_and_product_list = utils_en.read_string_to_list(category_and_product_response)\n",
        "    #print(category_and_product_list)\n",
        "\n",
        "    if debug: print(\"第二步：抽取出商品列表\")\n",
        "\n",
        "    # 第三步：查找商品对应信息\n",
        "    product_information = utils_en.generate_output_string(category_and_product_list)\n",
        "    if debug: print(\"第三步：查找抽取出的商品信息\")\n",
        "\n",
        "    # 第四步：根据信息生成回答\n",
        "    system_message = f\"\"\"\n",
        "    You are a customer service assistant for a large electronic store. \\\n",
        "    Respond in a friendly and helpful tone, with concise answers. \\\n",
        "    Make sure to ask the user relevant follow-up questions.\n",
        "    \"\"\"\n",
        "    # 插入 message\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': system_message},\n",
        "        {'role': 'user', 'content': f\"{delimiter}{user_input}{delimiter}\"},\n",
        "        {'role': 'assistant', 'content': f\"Relevant product information:\\n{product_information}\"}\n",
        "    ]\n",
        "    # 获取 GPT3.5 的回答\n",
        "    # 通过附加 all_messages 实现多轮对话\n",
        "    final_response = get_completion_from_messages(all_messages + messages)\n",
        "    if debug:print(\"第四步：生成用户回答\")\n",
        "    # 将该轮信息加入到历史信息中\n",
        "    all_messages = all_messages + messages[1:]\n",
        "\n",
        "    # 第五步：基于 Moderation API 检查输出是否合规\n",
        "    response = client.moderations.create(input=final_response)\n",
        "    moderation_output = response[\"results\"][0]\n",
        "\n",
        "    # 输出不合规\n",
        "    if moderation_output[\"flagged\"]:\n",
        "        if debug: print(\"第五步：输出被 Moderation 拒绝\")\n",
        "        return \"抱歉，我们不能提供该信息\"\n",
        "\n",
        "    if debug: print(\"第五步：输出经过 Moderation 检查\")\n",
        "\n",
        "    # 第六步：模型检查是否很好地回答了用户问题\n",
        "    user_message = f\"\"\"\n",
        "    Customer message: {delimiter}{user_input}{delimiter}\n",
        "    Agent response: {delimiter}{final_response}{delimiter}\n",
        "\n",
        "    Does the response sufficiently answer the question?\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': system_message},\n",
        "        {'role': 'user', 'content': user_message}\n",
        "    ]\n",
        "    # 要求模型评估回答\n",
        "    evaluation_response = get_completion_from_messages(messages)\n",
        "    if debug: print(\"第六步：模型评估该回答\")\n",
        "\n",
        "    # 第七步：如果评估为 Y，输出回答；如果评估为 N，反馈将由人工修正答案\n",
        "    if \"Y\" in evaluation_response:  # 使用 in 来避免模型可能生成 Yes\n",
        "        if debug: print(\"第七步：模型赞同了该回答.\")\n",
        "        return final_response, all_messages\n",
        "    else:\n",
        "        if debug: print(\"第七步：模型不赞成该回答.\")\n",
        "        neg_str = \"很抱歉，我无法提供您所需的信息。我将为您转接到一位人工客服代表以获取进一步帮助。\"\n",
        "        return neg_str, all_messages\n",
        "\n",
        "user_input = \"tell me about the smartx pro phone and the fotosnap camera, the dslr one. Also what tell me about your tvs\"\n",
        "response,_ = process_user_message(user_input,[])\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m789WMlv0mL4",
        "outputId": "a52389b8-47aa-4ad1-f5c7-682d33fccf86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "第一步：输入通过 Moderation 检查\n",
            "第二步：抽取出商品列表\n",
            "第三步：查找抽取出的商品信息\n",
            "第四步：生成用户回答\n",
            "第五步：输出经过 Moderation 检查\n",
            "第六步：模型评估该回答\n",
            "第七步：模型赞同了该回答.\n",
            "关于SmartX ProPhone和FotoSnap相机的信息：\n",
            "\n",
            "SmartX ProPhone是一款功能强大的智能手机，具有6.1英寸的显示屏，128GB的存储空间，12MP的双摄像头和5G网络。售价为899.99美元。\n",
            "\n",
            "FotoSnap相机系列包括DSLR相机、无反相机和即时相机。DSLR相机具有24.2MP传感器、1080p视频、3英寸LCD和可更换镜头。无反相机具有20.1MP传感器、4K视频、3英寸触摸屏和可更换镜头。即时相机可以即时打印照片，具有内置闪光灯、自拍镜和电池供电。售价分别为599.99美元、799.99美元和69.99美元。\n",
            "\n",
            "关于我们的电视：\n",
            "\n",
            "我们有多种电视可供选择，包括CineView 4K电视、CineView 8K电视和CineView OLED电视。CineView 4K电视具有55英寸的显示屏、4K分辨率、HDR和智能电视功能。CineView 8K电视具有65英寸的显示屏、8K分辨率、HDR和智能电视功能。CineView OLED电视具有55英寸的显示屏、4K分辨率、HDR和智能电视功能。我们还提供SoundMax家庭影院和SoundMax声音栏，以提供更好的音频体验。售价从199.99美元到2999.99美元不等，保修期为1年或2年。\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "注意：限于模型对中文理解能力较弱，中文 Prompt 可能会随机出现不成功，可以多次运行；也非常欢迎同学探究更稳定的中文 Prompt\n",
        "'''\n",
        "def process_user_message_ch(user_input, all_messages, debug=True):\n",
        "    \"\"\"\n",
        "    对用户信息进行预处理\n",
        "\n",
        "    参数:\n",
        "    user_input : 用户输入\n",
        "    all_messages : 历史信息\n",
        "    debug : 是否开启 DEBUG 模式,默认开启\n",
        "    \"\"\"\n",
        "    # 分隔符\n",
        "    delimiter = \"```\"\n",
        "\n",
        "    # 第一步: 使用 OpenAI 的 Moderation API 检查用户输入是否合规或者是一个注入的 Prompt\n",
        "    response = client.moderations.create(input=user_input)\n",
        "    moderation_output = response.results[0]\n",
        "\n",
        "    # 经过 Moderation API 检查该输入不合规\n",
        "    if moderation_output[\"flagged\"]:\n",
        "        print(\"第一步：输入被 Moderation 拒绝\")\n",
        "        return \"抱歉，您的请求不合规\"\n",
        "\n",
        "    # 如果开启了 DEBUG 模式，打印实时进度\n",
        "    if debug: print(\"第一步：输入通过 Moderation 检查\")\n",
        "\n",
        "    # 第二步：抽取出商品和对应的目录，类似于之前课程中的方法，做了一个封装\n",
        "    category_and_product_response = utils_zh.find_category_and_product_only(user_input, utils_zh.get_products_and_category())\n",
        "    #print(category_and_product_response)\n",
        "    # 将抽取出来的字符串转化为列表\n",
        "    category_and_product_list = utils_zh.read_string_to_list(category_and_product_response)\n",
        "    #print(category_and_product_list)\n",
        "\n",
        "    if debug: print(\"第二步：抽取出商品列表\")\n",
        "\n",
        "    # 第三步：查找商品对应信息\n",
        "    product_information = utils_zh.generate_output_string(category_and_product_list)\n",
        "    if debug: print(\"第三步：查找抽取出的商品信息\")\n",
        "\n",
        "    # 第四步：根据信息生成回答\n",
        "    system_message = f\"\"\"\n",
        "        您是一家大型电子商店的客户服务助理。\\\n",
        "        请以友好和乐于助人的语气回答问题，并提供简洁明了的答案。\\\n",
        "        请确保向用户提出相关的后续问题。\n",
        "    \"\"\"\n",
        "    # 插入 message\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': system_message},\n",
        "        {'role': 'user', 'content': f\"{delimiter}{user_input}{delimiter}\"},\n",
        "        {'role': 'assistant', 'content': f\"相关商品信息:\\n{product_information}\"}\n",
        "    ]\n",
        "    # 获取 GPT3.5 的回答\n",
        "    # 通过附加 all_messages 实现多轮对话\n",
        "    final_response = get_completion_from_messages(all_messages + messages)\n",
        "    if debug:print(\"第四步：生成用户回答\")\n",
        "    # 将该轮信息加入到历史信息中\n",
        "    all_messages = all_messages + messages[1:]\n",
        "\n",
        "    # 第五步：基于 Moderation API 检查输出是否合规\n",
        "    response = client.moderations.create(input=final_response)\n",
        "    moderation_output = response[\"results\"][0]\n",
        "\n",
        "    # 输出不合规\n",
        "    if moderation_output[\"flagged\"]:\n",
        "        if debug: print(\"第五步：输出被 Moderation 拒绝\")\n",
        "        return \"抱歉，我们不能提供该信息\"\n",
        "\n",
        "    if debug: print(\"第五步：输出经过 Moderation 检查\")\n",
        "\n",
        "    # 第六步：模型检查是否很好地回答了用户问题\n",
        "    user_message = f\"\"\"\n",
        "    用户信息: {delimiter}{user_input}{delimiter}\n",
        "    代理回复: {delimiter}{final_response}{delimiter}\n",
        "\n",
        "    回复是否足够回答问题\n",
        "    如果足够，回答 Y\n",
        "    如果不足够，回答 N\n",
        "    仅回答上述字母即可\n",
        "    \"\"\"\n",
        "    # print(final_response)\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': system_message},\n",
        "        {'role': 'user', 'content': user_message}\n",
        "    ]\n",
        "    # 要求模型评估回答\n",
        "    evaluation_response = get_completion_from_messages(messages)\n",
        "    # print(evaluation_response)\n",
        "    if debug: print(\"第六步：模型评估该回答\")\n",
        "\n",
        "    # 第七步：如果评估为 Y，输出回答；如果评估为 N，反馈将由人工修正答案\n",
        "    if \"Y\" in evaluation_response:  # 使用 in 来避免模型可能生成 Yes\n",
        "        if debug: print(\"第七步：模型赞同了该回答.\")\n",
        "        return final_response, all_messages\n",
        "    else:\n",
        "        if debug: print(\"第七步：模型不赞成该回答.\")\n",
        "        neg_str = \"很抱歉，我无法提供您所需的信息。我将为您转接到一位人工客服代表以获取进一步帮助。\"\n",
        "        return neg_str, all_messages\n",
        "\n",
        "user_input = \"请告诉我关于 smartx pro phone 和 the fotosnap camera 的信息。另外，请告诉我关于你们的tvs的情况。\"\n",
        "response,_ = process_user_message_ch(user_input,[])\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCC36OAI0mL5"
      },
      "source": [
        "### 2.2 持续收集用户和助手消息的函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5xbm1JC0mL5"
      },
      "source": [
        "实现一个可视化界面"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD15dbom0mL5"
      },
      "outputs": [],
      "source": [
        "def collect_messages_en(debug=False):\n",
        "    \"\"\"\n",
        "    用于收集用户的输入并生成助手的回答\n",
        "\n",
        "    参数：\n",
        "    debug: 用于觉得是否开启调试模式\n",
        "    \"\"\"\n",
        "    user_input = inp.value_input\n",
        "    if debug: print(f\"User Input = {user_input}\")\n",
        "    if user_input == \"\":\n",
        "        return\n",
        "    inp.value = ''\n",
        "    global context\n",
        "    # 调用 process_user_message 函数\n",
        "    #response, context = process_user_message(user_input, context, utils.get_products_and_category(),debug=True)\n",
        "    response, context = process_user_message(user_input, context, debug=False)\n",
        "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
        "    panels.append(\n",
        "        pn.Row('User:', pn.pane.Markdown(user_input, width=600)))\n",
        "    panels.append(\n",
        "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
        "\n",
        "    return pn.Column(*panels) # 包含了所有的对话信息"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Id1Giq2B0mL5"
      },
      "outputs": [],
      "source": [
        "# 调用中文 Prompt 版本\n",
        "def collect_messages_ch(debug=False):\n",
        "    \"\"\"\n",
        "    用于收集用户的输入并生成助手的回答\n",
        "\n",
        "    参数：\n",
        "    debug: 用于觉得是否开启调试模式\n",
        "    \"\"\"\n",
        "    user_input = inp.value_input\n",
        "    if debug: print(f\"User Input = {user_input}\")\n",
        "    if user_input == \"\":\n",
        "        return\n",
        "    inp.value = ''\n",
        "    global context\n",
        "    # 调用 process_user_message 函数\n",
        "    #response, context = process_user_message(user_input, context, utils.get_products_and_category(),debug=True)\n",
        "    response, context = process_user_message_ch(user_input, context, debug=False)\n",
        "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
        "    panels.append(\n",
        "        pn.Row('User:', pn.pane.Markdown(user_input, width=600)))\n",
        "    panels.append(\n",
        "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
        "\n",
        "    return pn.Column(*panels) # 包含了所有的对话信息"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbGmzPvw0mL5",
        "outputId": "242869e6-743c-4299-9223-72131d2c6d08"
      },
      "outputs": [
        {
          "data": {},
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.holoviews_exec.v0+json": "",
            "text/html": [
              "<div id='1002'>\n",
              "  <div class=\"bk-root\" id=\"5bec6a62-17e2-41a3-9212-7126da759786\" data-root-id=\"1002\"></div>\n",
              "</div>\n",
              "<script type=\"application/javascript\">(function(root) {\n",
              "  function embed_document(root) {\n",
              "    var docs_json = {\"052e8379-8146-4aee-8619-78e96d2427ee\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"ReactiveHTML1\",\"overrides\":[],\"properties\":[]},{\"extends\":null,\"module\":null,\"name\":\"FlexBox1\",\"overrides\":[],\"properties\":[{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_content\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_items\"},{\"default\":\"row\",\"kind\":null,\"name\":\"flex_direction\"},{\"default\":\"wrap\",\"kind\":null,\"name\":\"flex_wrap\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"justify_content\"}]},{\"extends\":null,\"module\":null,\"name\":\"GridStack1\",\"overrides\":[],\"properties\":[{\"default\":\"warn\",\"kind\":null,\"name\":\"mode\"},{\"default\":null,\"kind\":null,\"name\":\"ncols\"},{\"default\":null,\"kind\":null,\"name\":\"nrows\"},{\"default\":true,\"kind\":null,\"name\":\"allow_resize\"},{\"default\":true,\"kind\":null,\"name\":\"allow_drag\"},{\"default\":[],\"kind\":null,\"name\":\"state\"}]},{\"extends\":null,\"module\":null,\"name\":\"click1\",\"overrides\":[],\"properties\":[{\"default\":\"\",\"kind\":null,\"name\":\"terminal_output\"},{\"default\":\"\",\"kind\":null,\"name\":\"debug_name\"},{\"default\":0,\"kind\":null,\"name\":\"clears\"}]},{\"extends\":null,\"module\":null,\"name\":\"NotificationAreaBase1\",\"overrides\":[],\"properties\":[{\"default\":\"bottom-right\",\"kind\":null,\"name\":\"position\"},{\"default\":0,\"kind\":null,\"name\":\"_clear\"}]},{\"extends\":null,\"module\":null,\"name\":\"NotificationArea1\",\"overrides\":[],\"properties\":[{\"default\":[],\"kind\":null,\"name\":\"notifications\"},{\"default\":\"bottom-right\",\"kind\":null,\"name\":\"position\"},{\"default\":0,\"kind\":null,\"name\":\"_clear\"},{\"default\":[{\"background\":\"#ffc107\",\"icon\":{\"className\":\"fas fa-exclamation-triangle\",\"color\":\"white\",\"tagName\":\"i\"},\"type\":\"warning\"},{\"background\":\"#007bff\",\"icon\":{\"className\":\"fas fa-info-circle\",\"color\":\"white\",\"tagName\":\"i\"},\"type\":\"info\"}],\"kind\":null,\"name\":\"types\"}]},{\"extends\":null,\"module\":null,\"name\":\"Notification\",\"overrides\":[],\"properties\":[{\"default\":null,\"kind\":null,\"name\":\"background\"},{\"default\":3000,\"kind\":null,\"name\":\"duration\"},{\"default\":null,\"kind\":null,\"name\":\"icon\"},{\"default\":\"\",\"kind\":null,\"name\":\"message\"},{\"default\":null,\"kind\":null,\"name\":\"notification_type\"},{\"default\":false,\"kind\":null,\"name\":\"_destroyed\"}]},{\"extends\":null,\"module\":null,\"name\":\"TemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]},{\"extends\":null,\"module\":null,\"name\":\"MaterialTemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]}],\"roots\":{\"references\":[{\"attributes\":{\"children\":[{\"id\":\"1007\"}],\"height\":300,\"margin\":[0,0,0,0],\"min_height\":300,\"name\":\"Row00110\"},\"id\":\"1006\",\"type\":\"Row\"},{\"attributes\":{\"children\":[{\"id\":\"1003\"},{\"id\":\"1004\"},{\"id\":\"1006\"}],\"margin\":[0,0,0,0],\"name\":\"Column00112\"},\"id\":\"1002\",\"type\":\"Column\"},{\"attributes\":{\"children\":[{\"id\":\"1005\"}],\"margin\":[0,0,0,0],\"name\":\"Row00105\"},\"id\":\"1004\",\"type\":\"Row\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"Str00108\",\"text\":\"&lt;pre&gt; &lt;/pre&gt;\"},\"id\":\"1007\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"margin\":[5,10,5,10],\"max_length\":5000,\"placeholder\":\"Enter text here\\u2026\"},\"id\":\"1003\",\"type\":\"TextInput\"},{\"attributes\":{\"args\":{\"bidirectional\":false,\"properties\":{\"event:button_click\":\"loading\"},\"source\":{\"id\":\"1005\"},\"target\":{\"id\":\"1006\"}},\"code\":\"\\n    if ('event:button_click'.startsWith('event:')) {\\n      var value = true\\n    } else {\\n      var value = source['event:button_click'];\\n      value = value;\\n    }\\n    if (typeof value !== 'boolean' || source.labels !== ['Loading']) {\\n      value = true\\n    }\\n    var css_classes = target.css_classes.slice()\\n    var loading_css = ['pn-loading', 'arc']\\n    if (value) {\\n      for (var css of loading_css) {\\n        if (!(css in css_classes)) {\\n          css_classes.push(css)\\n        }\\n      }\\n    } else {\\n     for (var css of loading_css) {\\n        var index = css_classes.indexOf(css)\\n        if (index > -1) {\\n          css_classes.splice(index, 1)\\n        }\\n      }\\n    }\\n    target['css_classes'] = css_classes\\n    \",\"tags\":[[140330220591408,[null,\"event:button_click\"],[null,\"loading\"]]]},\"id\":\"1008\",\"type\":\"CustomJS\"},{\"attributes\":{\"client_comm_id\":\"2a4a5b3205d940a0b2a81401239356fc\",\"comm_id\":\"53327ab16d4d4b5a9937d0a053d6c7e0\",\"plot_id\":\"1002\"},\"id\":\"1009\",\"type\":\"panel.models.comm_manager.CommManager\"},{\"attributes\":{\"reload\":false},\"id\":\"1010\",\"type\":\"panel.models.location.Location\"},{\"attributes\":{\"icon\":null,\"js_event_callbacks\":{\"button_click\":[{\"id\":\"1008\"}]},\"label\":\"Service Assistant\",\"margin\":[5,10,5,10],\"subscribed_events\":[\"button_click\"]},\"id\":\"1005\",\"type\":\"Button\"}],\"root_ids\":[\"1002\",\"1009\",\"1010\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.3\"}};\n",
              "    var render_items = [{\"docid\":\"052e8379-8146-4aee-8619-78e96d2427ee\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"5bec6a62-17e2-41a3-9212-7126da759786\"}}];\n",
              "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "    for (const render_item of render_items) {\n",
              "      for (const root_id of render_item.root_ids) {\n",
              "\tconst id_el = document.getElementById(root_id)\n",
              "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
              "\t  const root_el = id_el.children[0]\n",
              "\t  root_el.id = root_el.id + '-rendered'\n",
              "\t}\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else if (document.readyState == \"complete\") {\n",
              "        attempts++;\n",
              "        if (attempts > 200) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 25, root)\n",
              "  }\n",
              "})(window);</script>"
            ],
            "text/plain": [
              "Column\n",
              "    [0] TextInput(placeholder='Enter text here…')\n",
              "    [1] Row\n",
              "        [0] Button(name='Service Assistant')\n",
              "    [2] ParamFunction(function, _pane=Str, height=300, loading_indicator=True)"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "application/vnd.holoviews_exec.v0+json": {
              "id": "1002"
            }
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "panels = [] # collect display\n",
        "\n",
        "# 系统信息\n",
        "context = [ {'role':'system', 'content':\"You are Service Assistant\"} ]\n",
        "\n",
        "inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
        "button_conversation = pn.widgets.Button(name=\"Service Assistant\")\n",
        "\n",
        "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
        "\n",
        "dashboard = pn.Column(\n",
        "    inp,\n",
        "    pn.Row(button_conversation),\n",
        "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
        ")\n",
        "\n",
        "dashboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGwpwSCG0mL6"
      },
      "source": [
        "通过监控系统在更多输入上的质量，您可以修改步骤，提高系统的整体性能。\n",
        "\n",
        "也许我们会发现，对于某些步骤，我们的提示可能更好，也许有些步骤甚至不必要，也许我们会找到更好的检索方法等等。\n",
        "\n",
        "我们将在下一章中进一步讨论这个问题。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}